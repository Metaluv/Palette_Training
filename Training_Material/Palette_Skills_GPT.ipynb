{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAKE SURE BASE IS ON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.organization = os.getenv(\"OPENAI_ORG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'As a professional python programmer & Data Scientist, I want you create a machine learning model for this data in the most optimal way utilizing your maximum response tokens. Check the formating before submitting. The first step would be to pre-process the data and to split it into training and testing sets. I would then standardize the data using a minmax scaler. After this, I would choose an appropriate machine learning model to fit this data. I would likely use some form of regression, such as Linear Regression, Ridge Regression, Lasso Regression, or Support Vector Regression. After selecting the model, I would train the model on the training set and evaluate it on the testing set. Finally, I would use hyperparameter tuning techniques, such as grid search, to fine-tune the model and find the best parameters that give the best performance. This is the data, complete the response in python:'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "import pandas as pd\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.preprocessing import MinMaxScaler\n",
      "from sklearn.linear_model import LinearRegression, Ridge, Lasso, SVR\n",
      "from sklearn.model_selection import GridSearchCV\n",
      "\n",
      "# Load the data\n",
      "data = pd.read_csv('data.csv')\n",
      "\n",
      "# Pre-process the data\n",
      "data.fillna(0, inplace = True)\n",
      "X = data.drop('Year', axis = 1).values\n",
      "y = data['Year'].values\n",
      "\n",
      "# Split the data into training and test sets\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
      "\n",
      "# Standardize the data using minmax scaler\n",
      "scaler = MinMaxScaler()\n",
      "X_train = scaler.fit_transform(X_train)\n",
      "X_test = scaler.transform(X_test)\n",
      "\n",
      "# Train the model \n",
      "# We will use a Ridge Regression model\n",
      "model = Ridge()\n",
      "model.fit(X_train, y_train)\n",
      "\n",
      "# Test the model\n",
      "score = model.score(X_test, y_test)\n",
      "\n",
      "# Use grid search to find the optimal hyperparameters\n",
      "parameters = {'alpha': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
      "grid_search = GridSearchCV(model, parameters, cv=5, scoring='r2')\n",
      "grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Print the optimal parameters\n",
      "print('Optimal parameters: {}'.format(grid_search.best_params_))\n",
      "\n",
      "# Print the best score achieved\n",
      "print('Best score: {}'.format(grid_search.best_score_))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read the subjects from the input file\n",
    "with open('input.txt', 'r') as file:\n",
    "    subjects = file.read()\n",
    "\n",
    "# Call the OpenAI API\n",
    "response = openai.Completion.create(\n",
    "    model=\"text-davinci-003\", \n",
    "    prompt=f\"{prompt}+{subjects}\",\n",
    "    max_tokens=3000,\n",
    "    n=1, \n",
    "    stop=None, \n",
    "    temperature=0.9\n",
    ")\n",
    "\n",
    "response_json = response.to_dict()\n",
    "response_text = response_json['choices'][0]['text']\n",
    "# Get the current time\n",
    "now = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "\n",
    "# Save the response text to a file\n",
    "with open(f\"ag_tech_{now}.txt\", \"w\") as f:\n",
    "    f.write(response_text)\n",
    "\n",
    "print(response_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5e820f3ddc028a719ffe50e7d80dd01658ce1fe998d4f6f388d9b09d11d3d164"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
